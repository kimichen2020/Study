{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学习笔记TF028:实现简单卷积网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入MNIST数据集。创建默认Interactive Session。\n",
    "\n",
    "初始化函数，权重制造随机噪声打破完全对称。截断正态分布噪声，标准差设0.1。ReLU，偏置加小正值(0.1)，避免死亡节点(dead neurons)。\n",
    "\n",
    "卷积层函数，tf.nn.conv2d，TensorFlow 2 维卷积函数，参数x输入，W卷积参数，卷积核尺寸，channel个数，卷积核数量(卷积层提取特征数量)。Strides卷积模板移动步长，全1代表不遗漏划过图片每一个点。Padding代表边界处理方式，SAME边界加Padding，卷积输出、输入保持同样尺寸。\n",
    "\n",
    "池化层函数，tf.nn.max_pool，TensorFlow 最大池化函数。2x2最大池化，2x2像素块降为1x1像素。最大池化保留原始像素块灰度值最高像素，保留最显著特征。strides设横竖方向2步长。\n",
    "\n",
    "定义输入placeholder，x特征，y真实label。卷积神经网络空间结构信息，1D输入向量，转为2D图片结构。尺寸[-1,28,28,1]。-1代表样本数量不固定。1代表颜色通道数量。tf.reshape tensor变形函数。\n",
    "\n",
    "第一个卷积层，卷积函数初始化，weights、bias。[5,5,1,32]代表卷积核尺寸5x5,1个颜色通道，32个不同卷积核。使用conv2d函数卷积操作，加偏置，使用ReLU激活函数非线性处理。使用最大池化函数max_pool_2x2池化操作卷积输出结果。\n",
    "\n",
    "第二个卷积层，卷积核64个，提取64种特征。经历两次步长2x2最大池化，边长只有1/4,图片尺寸28x28变7x7.第二个卷积层卷积核数量64,输出tensor尺寸7x7x64。使用tf.reshape函数对第二个卷积层输出tensor变形，转成1D向量，连接一个全连接层，隐含节点1024,使用ReLU激活函数。\n",
    "\n",
    "使用Dropout层减轻过拟合。Dropout，通过一个placeholder传入keep_prob比率控制。训练时，随机丢弃部分节点数据减轻过拟合，预测时保留全部数据追求最好预测性能。\n",
    "\n",
    "Dropout层输出连接Softmax层，得到最后概率输出。\n",
    "\n",
    "定义损失函数cross_entropy。优化器使用Adam，给予较小学习速率1e-4。\n",
    "\n",
    "定义评测准确率操作。\n",
    "\n",
    "训练，初始化所有参数，设置训练时Dropout的keep_prob比率0.5.使用大小50的mini-batch，进行20000次训练迭代，样本数量100万。每100次训练，评测准确率，keep_prob设1,实时监测模型性能。\n",
    "\n",
    "全部训练完成，测试集全面测试，得到整体分类准确率。\n",
    "\n",
    "99.2%准确率，卷积网络对图像特征提取抽象，卷积核权值共享。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.16\n",
      "step 100, training accuracy 0.86\n",
      "step 200, training accuracy 0.92\n",
      "step 300, training accuracy 0.94\n",
      "step 400, training accuracy 0.88\n",
      "step 500, training accuracy 0.9\n",
      "step 600, training accuracy 0.96\n",
      "step 700, training accuracy 0.9\n",
      "step 800, training accuracy 0.98\n",
      "step 900, training accuracy 1\n",
      "step 1000, training accuracy 0.98\n",
      "step 1100, training accuracy 1\n",
      "step 1200, training accuracy 0.98\n",
      "step 1300, training accuracy 0.98\n",
      "step 1400, training accuracy 0.94\n",
      "step 1500, training accuracy 0.98\n",
      "step 1600, training accuracy 1\n",
      "step 1700, training accuracy 1\n",
      "step 1800, training accuracy 0.96\n",
      "step 1900, training accuracy 0.98\n",
      "step 2000, training accuracy 1\n",
      "step 2100, training accuracy 0.98\n",
      "step 2200, training accuracy 1\n",
      "step 2300, training accuracy 0.96\n",
      "step 2400, training accuracy 0.98\n",
      "step 2500, training accuracy 1\n",
      "step 2600, training accuracy 1\n",
      "step 2700, training accuracy 1\n",
      "step 2800, training accuracy 0.94\n",
      "step 2900, training accuracy 1\n",
      "step 3000, training accuracy 1\n",
      "step 3100, training accuracy 1\n",
      "step 3200, training accuracy 0.94\n",
      "step 3300, training accuracy 0.98\n",
      "step 3400, training accuracy 1\n",
      "step 3500, training accuracy 0.98\n",
      "step 3600, training accuracy 1\n",
      "step 3700, training accuracy 1\n",
      "step 3800, training accuracy 1\n",
      "step 3900, training accuracy 0.94\n",
      "step 4000, training accuracy 1\n",
      "step 4100, training accuracy 1\n",
      "step 4200, training accuracy 0.98\n",
      "step 4300, training accuracy 1\n",
      "step 4400, training accuracy 0.98\n",
      "step 4500, training accuracy 1\n",
      "step 4600, training accuracy 0.98\n",
      "step 4700, training accuracy 0.98\n",
      "step 4800, training accuracy 0.94\n",
      "step 4900, training accuracy 0.98\n",
      "step 5000, training accuracy 1\n",
      "step 5100, training accuracy 0.98\n",
      "step 5200, training accuracy 1\n",
      "step 5300, training accuracy 0.98\n",
      "step 5400, training accuracy 1\n",
      "step 5500, training accuracy 1\n",
      "step 5600, training accuracy 0.98\n",
      "step 5700, training accuracy 1\n",
      "step 5800, training accuracy 0.98\n",
      "step 5900, training accuracy 0.98\n",
      "step 6000, training accuracy 0.98\n",
      "step 6100, training accuracy 0.98\n",
      "step 6200, training accuracy 0.98\n",
      "step 6300, training accuracy 0.96\n",
      "step 6400, training accuracy 0.98\n",
      "step 6500, training accuracy 1\n",
      "step 6600, training accuracy 1\n",
      "step 6700, training accuracy 1\n",
      "step 6800, training accuracy 1\n",
      "step 6900, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 7100, training accuracy 1\n",
      "step 7200, training accuracy 1\n",
      "step 7300, training accuracy 1\n",
      "step 7400, training accuracy 1\n",
      "step 7500, training accuracy 1\n",
      "step 7600, training accuracy 0.98\n",
      "step 7700, training accuracy 1\n",
      "step 7800, training accuracy 0.98\n",
      "step 7900, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 8100, training accuracy 0.98\n",
      "step 8200, training accuracy 0.96\n",
      "step 8300, training accuracy 1\n",
      "step 8400, training accuracy 1\n",
      "step 8500, training accuracy 1\n",
      "step 8600, training accuracy 0.98\n",
      "step 8700, training accuracy 1\n",
      "step 8800, training accuracy 1\n",
      "step 8900, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 9100, training accuracy 1\n",
      "step 9200, training accuracy 1\n",
      "step 9300, training accuracy 0.98\n",
      "step 9400, training accuracy 0.98\n",
      "step 9500, training accuracy 0.98\n",
      "step 9600, training accuracy 1\n",
      "step 9700, training accuracy 1\n",
      "step 9800, training accuracy 0.98\n",
      "step 9900, training accuracy 1\n",
      "step 10000, training accuracy 0.98\n",
      "step 10100, training accuracy 0.98\n",
      "step 10200, training accuracy 1\n",
      "step 10300, training accuracy 1\n",
      "step 10400, training accuracy 1\n",
      "step 10500, training accuracy 1\n",
      "step 10600, training accuracy 1\n",
      "step 10700, training accuracy 0.98\n",
      "step 10800, training accuracy 1\n",
      "step 10900, training accuracy 1\n",
      "step 11000, training accuracy 1\n",
      "step 11100, training accuracy 1\n",
      "step 11200, training accuracy 0.98\n",
      "step 11300, training accuracy 1\n",
      "step 11400, training accuracy 1\n",
      "step 11500, training accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "# 载入MNIST数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# 创建默认Interactive Session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 初始化函数，权重制造随机噪声打破完全对称。\n",
    "# 截断正态分布噪声，标准差设0.1。\n",
    "# ReLU，偏置加小正值(0.1)，避免死亡节点(dead neurons)。\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 卷积层函数，tf.nn.conv2d，TensorFlow 2 维卷积函数\n",
    "# 参数x输入，W卷积参数\n",
    "# 卷积核尺寸，channel个数，卷积核数量(卷积层提取特征数量)。\n",
    "# Strides卷积模板移动步长，全1代表不遗漏划过图片每一个点。P\n",
    "# adding代表边界处理方式，SAME边界加Padding，卷积输出、输入保持同样尺寸。\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# 池化层函数，tf.nn.max_pool，TensorFlow 最大池化函数。\n",
    "# 2x2最大池化，2x2像素块降为1x1像素。\n",
    "# 最大池化保留原始像素块灰度值最高像素，保留最显著特征。\n",
    "# strides设横竖方向2步长。\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                         strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# 定义输入placeholder，x特征，y真实label。\n",
    "# 卷积神经网络空间结构信息，1D输入向量，转为2D图片结构。\n",
    "# 尺寸[-1,28,28,1]。-1代表样本数量不固定。\n",
    "# 1代表颜色通道数量。tf.reshape tensor变形函数。\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# 第一个卷积层，卷积函数初始化，weights、bias。\n",
    "# [5,5,1,32]代表卷积核尺寸5x5,1个颜色通道，32个不同卷积核。\n",
    "# 使用conv2d函数卷积操作，加偏置，使用ReLU激活函数非线性处理。\n",
    "# 使用最大池化函数max_pool_2x2池化操作卷积输出结果。\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# 第二个卷积层，卷积核64个，提取64种特征。\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# 经历两次步长2x2最大池化，边长只有1/4,图片尺寸28x28变7x7.\n",
    "# 第二个卷积层卷积核数量64,输出tensor尺寸7x7x64。\n",
    "# 使用tf.reshape函数对第二个卷积层输出tensor变形，转成1D向量\n",
    "# 连接一个全连接层，隐含节点1024,使用ReLU激活函数。\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# 使用Dropout层减轻过拟合。\n",
    "# Dropout，通过一个placeholder传入keep_prob比率控制。\n",
    "# 训练时，随机丢弃部分节点数据减轻过拟合，预测时保留全部数据追求最好预测性能。\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "# Dropout层输出连接Softmax层，得到最后概率输出。\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# 定义损失函数cross_entropy。\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "\n",
    "# 优化器使用Adam，给予较小学习速率1e-4。\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# 定义评测准确率操作。\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 训练，初始化所有参数，设置训练时Dropout的keep_prob比率0.5。\n",
    "# 使用大小50的mini-batch，进行20000次训练迭代，样本数量100万。\n",
    "# 每100次训练，评测准确率，keep_prob设1,实时监测模型性能。\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "# 全部训练完成，测试集全面测试，得到整体分类准确率\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, \n",
    "                                                  y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
